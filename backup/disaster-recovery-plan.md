# DISASTER RECOVERY PLAN - WOJNY LASEROWE

## 游꿢 CEL
**RTO (Recovery Time Objective):** 4 godziny  
**RPO (Recovery Point Objective):** 1 godzina  
**Availability Target:** 99.9% (8.76 godzin przestoju/rok)

---

## 游늶 SCENARIUSZE AWARII

### 1. **DATABASE FAILURE**
**Przyczyna:** Hardware failure, corruption, network issues  
**Impact:** Aplikacja niedost캧pna, dane u콮ytkownik칩w zagro콮one

#### Recovery Procedure:
```bash
# 1. Sprawd콬 status bazy danych
kubectl get pods -n production | grep postgres

# 2. Je콑li pod nie dzia켹a, sprawd콬 logi
kubectl logs -n production postgres-deployment-xxx

# 3. Przywr칩캖 z backupu (je콑li konieczne)
kubectl exec -it postgres-backup-job-xxx -n production -- /bin/bash
gunzip -c /backup/YYYYMMDD/full_backup_YYYYMMDD_HHMMSS.sql.gz | psql -h postgres-service -U postgres -d wojny_laserowe

# 4. Sprawd콬 integralno콑캖 danych
kubectl exec -it postgres-backup-job-xxx -n production -- psql -h postgres-service -U postgres -d wojny_laserowe -c "SELECT COUNT(*) FROM users;"
```

### 2. **APPLICATION FAILURE**
**Przyczyna:** Code bug, memory leak, resource exhaustion  
**Impact:** Aplikacja niedost캧pna dla u콮ytkownik칩w

#### Recovery Procedure:
```bash
# 1. Sprawd콬 status aplikacji
kubectl get pods -n production | grep wojny-laserowe

# 2. Sprawd콬 logi aplikacji
kubectl logs -n production wojny-laserowe-deployment-xxx

# 3. Restart aplikacji
kubectl rollout restart deployment/wojny-laserowe -n production

# 4. Sprawd콬 czy aplikacja dzia켹a
kubectl get pods -n production | grep wojny-laserowe
curl -f http://localhost:3000/api/health
```

### 3. **INFRASTRUCTURE FAILURE**
**Przyczyna:** Node failure, network issues, cluster failure  
**Impact:** Ca켹a aplikacja niedost캧pna

#### Recovery Procedure:
```bash
# 1. Sprawd콬 status klastra
kubectl get nodes
kubectl get pods --all-namespaces

# 2. Je콑li node nie dzia켹a, usu켻 go
kubectl delete node <node-name>

# 3. Sprawd콬 czy pody s캔 reschedulowane
kubectl get pods -n production

# 4. Je콑li konieczne, przywr칩캖 z backupu
kubectl apply -f backup/postgres-backup.yaml
kubectl apply -f backup/redis-backup.yaml
```

### 4. **SECURITY BREACH**
**Przyczyna:** Unauthorized access, data breach  
**Impact:** Dane u콮ytkownik칩w zagro콮one

#### Recovery Procedure:
```bash
# 1. Natychmiastowe odci캧cie dost캧pu
kubectl scale deployment wojny-laserowe --replicas=0 -n production

# 2. Zmie켻 wszystkie has켹a i klucze
kubectl create secret generic postgres-secret --from-literal=password=<new-password> -n production --dry-run=client -o yaml | kubectl apply -f -

# 3. Sprawd콬 logi bezpiecze켻stwa
kubectl logs -n production | grep -i "unauthorized\|breach\|attack"

# 4. Przywr칩캖 z czystego backupu
kubectl exec -it postgres-backup-job-xxx -n production -- gunzip -c /backup/YYYYMMDD/full_backup_YYYYMMDD_HHMMSS.sql.gz | psql -h postgres-service -U postgres -d wojny_laserowe

# 5. Uruchom ponownie aplikacj캧
kubectl scale deployment wojny-laserowe --replicas=3 -n production
```

---

## 游댃 FAILOVER PROCEDURES

### 1. **AUTOMATIC FAILOVER**
- **Kubernetes:** Automatyczne reschedulowanie pod칩w
- **PostgreSQL:** Master-slave replication (je콑li skonfigurowane)
- **Redis:** Redis Sentinel (je콑li skonfigurowane)

### 2. **MANUAL FAILOVER**
```bash
# 1. Sprawd콬 status us켹ug
kubectl get services -n production

# 2. Przekieruj ruch na backup
kubectl patch service wojny-laserowe-service -n production -p '{"spec":{"selector":{"app":"wojny-laserowe-backup"}}}'

# 3. Sprawd콬 czy failover dzia켹a
curl -f http://localhost:3000/api/health
```

---

## 游늵 MONITORING I ALERTING

### 1. **CRITICAL ALERTS**
- Pod down > 5 minut
- Database connection failure
- High error rate > 5%
- Disk space > 90%

### 2. **ESCALATION MATRIX**
```
Level 1 (0-15 min): DevOps Engineer
Level 2 (15-30 min): Tech Lead
Level 3 (30+ min): CTO + Management
```

### 3. **COMMUNICATION PLAN**
- **Slack:** #incidents channel
- **Email:** incidents@wojny-laserowe.com
- **Phone:** On-call rotation

---

## 游빍 TESTING PROCEDURES

### 1. **MONTHLY DR TEST**
```bash
# 1. Backup test
kubectl create job backup-test-$(date +%Y%m%d) --from=cronjob/postgres-backup -n production

# 2. Restore test
kubectl create job restore-test-$(date +%Y%m%d) --from=cronjob/backup-verification -n production

# 3. Failover test
kubectl scale deployment wojny-laserowe --replicas=0 -n production
kubectl scale deployment wojny-laserowe --replicas=3 -n production
```

### 2. **QUARTERLY FULL DR TEST**
- Complete infrastructure failure simulation
- Full restore from backups
- End-to-end application testing
- Performance validation

---

## 游 CONTACTS

### **ON-CALL ROTATION**
- **Week 1:** DevOps Engineer A
- **Week 2:** DevOps Engineer B
- **Week 3:** Tech Lead
- **Week 4:** CTO

### **EXTERNAL CONTACTS**
- **Cloud Provider:** AWS Support
- **Database:** PostgreSQL Support
- **Monitoring:** Grafana Support

---

## 游늶 POST-INCIDENT REVIEW

### 1. **INCIDENT REPORT**
- Timeline of events
- Root cause analysis
- Impact assessment
- Recovery time

### 2. **IMPROVEMENT ACTIONS**
- Process improvements
- Tool enhancements
- Training needs
- Documentation updates

### 3. **LESSONS LEARNED**
- What went well
- What could be improved
- Action items for next time

---

## 游댢 RECOVERY TOOLS

### **BACKUP RESTORATION**
```bash
# PostgreSQL
gunzip -c backup.sql.gz | psql -h host -U user -d database

# Redis
redis-cli -h host -p port --rdb backup.rdb

# Application
tar -xzf app_backup.tar.gz -C /app/
```

### **MONITORING COMMANDS**
```bash
# Check application health
kubectl get pods -n production
kubectl logs -n production deployment/wojny-laserowe

# Check database status
kubectl exec -it postgres-pod -n production -- psql -c "SELECT 1;"

# Check Redis status
kubectl exec -it redis-pod -n production -- redis-cli ping
```

---

**Last Updated:** 2025-01-27  
**Next Review:** 2025-02-27  
**Version:** 1.0
